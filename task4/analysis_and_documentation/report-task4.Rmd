---
title: "R Notebook"
output: html_notebook
---
```A brief introduction to the dataset```
This data set is about ratings of candies for 2015,2016 and 2017.
It also contains many other questions that aren't related to candies. 

```A list of any assumptions you have made```
I made many assumptions throught out the cleaning.
1-Age 
I took anything greater than 120 and below 0 as NA. Although doing this 
does seem to mess up my analysis. As I have a very high average of people 
when when out trick or treat. 
2-Country
I picked out and cleaned all the obvious countries, ie.typo and "Handed-picked" all the 
stupid but was easy to guess countries. All the rest are hard to guess for human so
I treated them as NA.
3-Sweets
I put all the colored M&M into regular M&M, 
All Mary Janes(black orange warpper)as Mary Janes,
Bonker in 2015 was sweets, I changed all the sweets Bonkers to just Bonkers
Sweetums (a friend to diabetes) and Sweetums are same thing 
Non-sweets were all removed.
4-General 
I only kept the data that is related to candies and kepe only year from timestamp 
I also added year to 2017's data.

```The steps you took to clean the data (you don’t need to write out in detail every step, but a combination of commented code chunks with surrounding overall explanations would be great).```
1-Rough cleaning 
I needed to take a look at the data first, but it was way too messy to even
just have a quick look. I know we are working on sweets, so my first steps 
were getting all the sweets columns together. 
2015 and 2016 had [] around the names so I also tidied that.
```{r}
#candy_15 <- candy_15 %>% 
  #pivot_longer(cols = starts_with("["),
             #names_to = "sweets",
             #values_to = "emotion") %>% 
  #mutate(sweets = str_sub(sweets, 2, -2))
```
2-After I had a look at the tables, I decided to change the names to a shorter 
form. I didn't do clean_names() here as it won't help.
At this stage I picked and kept the columns that I needed. 
```{r}
#candy_15 <- candy_15 %>% 
  #rename(`age` = `How old are you?`,
         #`going_out` = `Are you going actually going trick or treating yourself?`)
#candy_15 <- candy_15 %>% 
  #select(cols = -c(4:29))
```
3- Cleaning specific columns, I worked with regx then realised how inefficient it
was, I created lists for US, UK,Canada and some other countries
I recoded the list to the tidy country names or NA.
I changed the strings to title case first, so I chanegd UAE back to all capital 
at the end. 
following is just to show mt method. the lists and codes are very long.
```{r}
#list_us <- c('all us')
#list_uk <- c('all uk')
#list_can <-c("all canada")
#list_NA <- c("na")

#candy_16 <- candy_16 %>% 
  #mutate(country = str_to_title(country)) %>% 
  #mutate(country = case_when(
                             #country %in% list_uk ~ "UK",
                             #country %in% list_us ~"US",
                             #country %in% list_can ~"Canada",
                             #country %in% list_NA ~ NA_character_,
                             #country =="Uae" ~"UAE",
                             #TRUE ~ country))

```
cleaned age and years,
I didn't realised that the age column was messy until I worked on the 
questions and got inf as my answer. I should have checked it before. 
I went back and changed the age to integer and I kept all age between 1 and 119.
it's not too good as a range. 
I also noticed that we will be working on years and I don't want to keep
all the timestamp. so for 2015 and 2016, I changed the timestamp to the year
and added a time stamp column to 2017. 
I only kept the useful information
```{r}
#candy_15_s <- candy_15_s %>% 
  #mutate(age = case_when(age >= 120 ~ NA_integer_,
                         #age <= 0 ~ NA_integer_,
                         #TRUE ~ age))

#candy_17_s <- candy_17 %>% 
  #mutate(Timestamp = "2017") %>% 
  #mutate(age = as.integer(age)) %>% 
  #select(c(2,3,4,5,11,12,13))
```
I tidied the sweets columns with a similar method, I created lists of NA
which are not sweets and put some "same" candy to one name, 
I also decided that blue/red/green M&M are just M&M. 
```{r}
#candy_15_s <- candy_15_s %>%
  #mutate(sweets = case_when(sweets %in% candy_na ~ NA_character_,
                             #sweets %in% candy_mm ~"Regular M&M",
                             #sweets %in% candy_mj ~ "Mary Janes",
                            #sweets %in% candy_l ~ "Licorice",
                            #sweets %in% candy_b ~ "Bonkers",
                            #sweets %in% candy_st ~ 'Sweetums',
                             #TRUE ~ sweets)) %>% 
  #arrange(sweets)
```


```The answers to the questions presented in the task brief```
What is the total number of candy ratings given across the three years. (Number of candy ratings, not the number of raters. Don’t count missing values)
  _72352 ratings were giving out throughout the three years._ 
 
What was the average age of people who are going out trick or treating?
_35?????ummmmmmmm very strange. But I kept all the age between 0 to 119._

What was the average age of people who are not going trick or treating?
_39 average age _

For each of joy, despair and meh, which candy bar received the most of these ratings?
_Mary Janes is most-DESPAIR	with count 10677_
_Regular M&M is most-joy with count	11138_
_Regular M&M	is most - MEH with count 4309_

How many people rated Starburst as despair?
_1990 in total across 3 years._

For the next three questions, count despair as -1, joy as +1, and meh as 0.
What was the most popular candy bar by this rating system for each gender in the dataset ?
_It's all regular M&M.. I did put all the M&M together.... _
_2064 votes in Female,_
_176 for I'd rather not say_
_3485 for male_
_other 86_

What was the most popular candy bar in each year?
_any full-size candy bar for 2015 4603 votes_
_regular M&M for 2016 and 2017 with 1705 and 4150 votes_

What was the most popular candy bar by this rating for people in US, Canada, UK, and all other countries?
_All M&M again..... Canada 600, other 114, UK 91 and US 4939_

```Any other interesting analyses or conclusions you come across.```

_most of the stupid name input are from the US...._

_when I did the analysis the first time I didn't tidy the sweets names,_ 
_the results were so different, also I imaging if I didn't put the M&M together_ 
_it will also be very different_

