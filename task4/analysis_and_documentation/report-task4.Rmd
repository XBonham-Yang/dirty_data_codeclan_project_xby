---
title: "R Notebook"
output: html_notebook
---
```A brief introduction to the dataset```
This data set is about ratings of candies for 2015,2016 and 2017.
It also contains many other questions that aren't related to candies. 

```A list of any assumptions you have made```
I made many assumptions throught out the cleaning.
1-Age 
I took anything greater than 120 and below 0 as NA. Although doing this 
does seem to mess up my analysis. As I have a very high average of people 
when when out trick or treat. 
2-Country
I picked out and cleaned all the obvious countries, ie.typo and "Handed-picked" all the 
stupid but was easy to guess countries. All the rest are hard to guess for human so
I treated them as NA.
3 General 
I only kept the data that is related to candies and kepe only year from timestamp 
I also added year to 2017's data.

```The steps you took to clean the data (you don’t need to write out in detail every step, but a combination of commented code chunks with surrounding overall explanations would be great).```
1-Rough cleaning 
I needed to take a look at the data first, but it was way too messy to even
just have a quick look. I know we are working on sweets, so my first steps 
were getting all the sweets columns together. 
2015 and 2016 had [] around the names so I also tidied that.
```{r}
#candy_15 <- candy_15 %>% 
  #pivot_longer(cols = starts_with("["),
             #names_to = "sweets",
             #values_to = "emotion") %>% 
  #mutate(sweets = str_sub(sweets, 2, -2))
```
2-After I had a look at the tables, I decided to change the names to a shorter 
form. I didn't do clean_names() here as it won't help.
At this stage I picked and kept the columns that I needed. 
```{r}
#candy_15 <- candy_15 %>% 
  #rename(`age` = `How old are you?`,
         #`going_out` = `Are you going actually going trick or treating yourself?`)
#candy_15 <- candy_15 %>% 
  #select(cols = -c(4:29))
```
3- Cleaning specific columns, I worked with regx then realised how inefficient it
was, but it does help me tidy up some countries so I kept some of the regx which
was bit lazy of me....I created 4 lists, US, UK, Canada and NA, I looked at 
the questions and decided that it's worthy focus on those countries. 
after I created the lists, i recode the list to the tidy country names or NA.
I changed the strings to title case first, so I chanegd UAE back to all capital 
at the end. 
following is just to show mt method. the lists and codes are very long.
```{r}
#list_us <- c('all us')
#list_uk <- c('all uk')
#list_can <-c("all canada")
#list_NA <- c("na")

#candy_16 <- candy_16 %>% 
  #mutate(country = str_to_title(country)) %>% 
  #mutate(country = case_when(str_detect(country, '(?i)usa') ~ "US",
                             #str_detect(country, '(?i)uk') ~"UK",
                             #str_detect(country, '(?i)canada') ~ "Canada",
                             #country %in% list_uk ~ "UK",
                             #country %in% list_us ~"US",
                             #country %in% list_can ~"Canada",
                             #country %in% list_NA ~ NA_character_,
                             #country =="Uae" ~"UAE",
                             #TRUE ~ country))

```
cleaned age and years,
I didn't realised that the age column was messy until I worked on the 
questions and got inf as my answer. I should have checked it before. 
I went back and changed the age to integer and I kept all age between 1 and 119.
it's not too good as a range. 
I also noticed that we will be working on years and I don't want to keep
all the timestamp. so for 2015 and 2016, I changed the timestamp to the year
and added a timestamp column to 2017. 
```{r}
#candy_17_s <- candy_17 %>% 
  #mutate(Timestamp = "2017") %>% 
  #mutate(age = as.integer(age))

#candy_all <- candy_all %>%
 #mutate(age = case_when(age >= 120 ~ NA_integer_,
                        #age <= 0 ~ NA_integer_,
                        #TRUE ~ age))
```


```The answers to the questions presented in the task brief```
What is the total number of candy ratings given across the three years. (Number of candy ratings, not the number of raters. Don’t count missing values)
 _1299017 ratings were giving out throughout the three years._
 
What was the average age of people who are going out trick or treating?
_36?????ummmmmmmm very strange. I did keep a lot of "oddly old age"_

What was the average age of people who are not going trick or treating?
_41 average age_

For each of joy, despair and meh, which candy bar received the most of these ratings?
_Broken glow stick is most-DESPAIR	with count 12780_
_Any full-sized candy bar is most-joy with count	12266_	
_Lollipops	is most - MEH with count 4363_	

How many people rated Starburst as despair?
_2887 in total across 3 years._

For the next three questions, count despair as -1, joy as +1, and meh as 0.
What was the most popular candy bar by this rating system for each gender in the dataset ?
_female- any full-sized candy bar with 2486 points_
_I'd rather not say also full-size candy bar with 218 points_
_male the same with 4362 points_
_other the same candy with 108 points_

What was the most popular candy bar in each year?
_any full-size candy bar every year..._
_with 4603 in 2015,1037 in 2016 and 6168 in 2017._

What was the most popular candy bar by this rating for people in US, Canada, UK, and all other countries?
_Canada/other/us the most popular candy is any full-sized candy bar with 685/160/6139_
_UK is Rolos with 96_

```Any other interesting analyses or conclusions you come across.```
_most of the stupid name input are from the US...._
_any full_size candy bar is oddly popular but does it even count?_ 


